{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cff8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from typing import Literal, Sequence, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc6c23",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cebce4",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, frequency_threshold: Union[int, float] = 0):\n",
    "        \"\"\"\n",
    "        Initializes the Vocabulary object with a frequency threshold.\n",
    "\n",
    "        Args:\n",
    "            frequency_threshold (Union[int, float]): The frequency threshold for including words in the vocabulary.\n",
    "                If an integer is provided, it represents the minimum number of occurrences a word must have to be included.\n",
    "                If a float is provided, it must be between 0 and 1, representing the minimum frequency proportion a word must have to be included.\n",
    "        \"\"\"\n",
    "        self.index2str = {0: '<PAD>', 1: '<UNK>', 2: '<SOS>', 3: '<EOS>'}\n",
    "        self.str2index = {v: k for k, v in self.index2str.items()}\n",
    "        self.freq_threshold = frequency_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index2str)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenize(text: str):\n",
    "        spacy_eng = spacy.load('en_core_web_sm')\n",
    "        return [token.text.lower() for token in spacy_eng.tokenizer(text)]\n",
    "    \n",
    "    def build_vocab(self, texts: Sequence[str]):\n",
    "        token_cnt = {}\n",
    "        for text in texts:\n",
    "            for token in self.tokenize(text):\n",
    "                if token not in token_cnt:\n",
    "                    token_cnt[token] = 1\n",
    "                else:\n",
    "                    token_cnt[token] += 1\n",
    "\n",
    "        if isinstance(self.freq_threshold, int):\n",
    "            tokens = [k for k, v in token_cnt.items()  if v > self.freq_threshold]\n",
    "        else:\n",
    "            total_cnt = sum([v for k,v in token_cnt.imtes()])\n",
    "            tokens = [k for k, v in token_cnt.items() if v / total_cnt >= self.freq_threshold]\n",
    "\n",
    "        for idx, token in enumerate(tokens):\n",
    "            self.index2str[idx + 4] = token\n",
    "            self.str2index[token] = idx + 4\n",
    "\n",
    "    def numericalize(self, text: str):\n",
    "        tokens = self.tokenize(text)\n",
    "\n",
    "        return [self.str2index[t] if t in self.str2index else self.str2index['<UNK>'] for t in tokens]\n",
    "        \n",
    "\n",
    "class AGNewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    AGNewsDataset is a custom Dataset class for loading and processing the AG News dataset.\n",
    "    \n",
    "    The dataset file must be in .csv format and should be located in the specified data directory.\n",
    "    The .csv file should contain the following columns:\n",
    "    \n",
    "    - 'Class Index': The category label of the news article (e.g., World, Sports, Business, Sci/Tech).\n",
    "    - 'Title': The title of the news article.\n",
    "    - 'Description': The description or content of the news article.\n",
    "    \n",
    "    The class supports loading both training and testing splits of the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    _LABEL = 'Class Index'\n",
    "    _TITLE = 'Title'\n",
    "    _DESCRIPTION = 'Description'\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: str,\n",
    "                 get_title: bool = False,\n",
    "                 max_sentece_len: int = 100,\n",
    "                 max_document_len: int = 40,\n",
    "                 split: Literal['train', 'test'] = 'train'):\n",
    "        \"\"\"\n",
    "        Initializes the AGNewsDataset object by loading and processing the dataset from the specified directory.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): The directory where the dataset .csv file is located.\n",
    "            get_title (bool): If True, the title of the news article will be concatenated with the description. Default is False.\n",
    "            max_sentece_len (int): The maximum words of a sentence. Default is 100.\n",
    "            max_document_len (int): The maximum sentences of a document. Default is 40.\n",
    "            split (Literal['train', 'test']): The dataset split to load, either 'train' or 'test'. Default is 'train'.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # get data\n",
    "        df = pd.read_csv(os.path.join(data_dir, f'{split}.csv'))\n",
    "        \n",
    "        self.labels = df.loc[:, self._LABEL].tolist()\n",
    "        \n",
    "        if get_title:\n",
    "            df[self._DESCRIPTION] = df[self._TITLE] + '\\n' + df[self._DESCRIPTION]\n",
    "        self.texts = df.loc[:, self._DESCRIPTION].tolist()\n",
    "\n",
    "        # create vocab and tokenizer\n",
    "        self.vocab = Vocabulary()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get label\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # get setences and words\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
